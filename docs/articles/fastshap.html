<!DOCTYPE html>
<!-- Generated by pkgdown: do not edit by hand --><html lang="en">
<head>
<meta http-equiv="Content-Type" content="text/html; charset=UTF-8">
<meta charset="utf-8">
<meta http-equiv="X-UA-Compatible" content="IE=edge">
<meta name="viewport" content="width=device-width, initial-scale=1.0">
<title>fastshap • fastshap</title>
<!-- favicons --><link rel="icon" type="image/png" sizes="16x16" href="../favicon-16x16.png">
<link rel="icon" type="image/png" sizes="32x32" href="../favicon-32x32.png">
<link rel="apple-touch-icon" type="image/png" sizes="180x180" href="../apple-touch-icon.png">
<link rel="apple-touch-icon" type="image/png" sizes="120x120" href="../apple-touch-icon-120x120.png">
<link rel="apple-touch-icon" type="image/png" sizes="76x76" href="../apple-touch-icon-76x76.png">
<link rel="apple-touch-icon" type="image/png" sizes="60x60" href="../apple-touch-icon-60x60.png">
<!-- jquery --><script src="https://cdnjs.cloudflare.com/ajax/libs/jquery/3.3.1/jquery.min.js" integrity="sha256-FgpCb/KJQlLNfOu91ta32o/NMZxltwRo8QtmkMRdAu8=" crossorigin="anonymous"></script><!-- Bootstrap --><link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/twitter-bootstrap/3.3.7/css/bootstrap.min.css" integrity="sha256-916EbMg70RQy9LHiGkXzG8hSg9EdNy97GazNG/aiY1w=" crossorigin="anonymous">
<script src="https://cdnjs.cloudflare.com/ajax/libs/twitter-bootstrap/3.3.7/js/bootstrap.min.js" integrity="sha256-U5ZEeKfGNOja007MMD3YBI0A3OSZOQbeG6z2f2Y0hu8=" crossorigin="anonymous"></script><!-- Font Awesome icons --><link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/5.7.1/css/all.min.css" integrity="sha256-nAmazAk6vS34Xqo0BSrTb+abbtFlgsFK7NKSi6o7Y78=" crossorigin="anonymous">
<link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/5.7.1/css/v4-shims.min.css" integrity="sha256-6qHlizsOWFskGlwVOKuns+D1nB6ssZrHQrNj1wGplHc=" crossorigin="anonymous">
<!-- clipboard.js --><script src="https://cdnjs.cloudflare.com/ajax/libs/clipboard.js/2.0.4/clipboard.min.js" integrity="sha256-FiZwavyI2V6+EXO1U+xzLG3IKldpiTFf3153ea9zikQ=" crossorigin="anonymous"></script><!-- headroom.js --><script src="https://cdnjs.cloudflare.com/ajax/libs/headroom/0.9.4/headroom.min.js" integrity="sha256-DJFC1kqIhelURkuza0AvYal5RxMtpzLjFhsnVIeuk+U=" crossorigin="anonymous"></script><script src="https://cdnjs.cloudflare.com/ajax/libs/headroom/0.9.4/jQuery.headroom.min.js" integrity="sha256-ZX/yNShbjqsohH1k95liqY9Gd8uOiE1S4vZc+9KQ1K4=" crossorigin="anonymous"></script><!-- pkgdown --><link href="../pkgdown.css" rel="stylesheet">
<script src="../pkgdown.js"></script><meta property="og:title" content="fastshap">
<meta property="og:description" content="">
<meta property="og:image" content="/logo.png">
<meta name="twitter:card" content="summary">
<!-- mathjax --><script src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.5/MathJax.js" integrity="sha256-nvJJv9wWKEm88qvoQl9ekL2J+k/RWIsaSScxxlsrv8k=" crossorigin="anonymous"></script><script src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.5/config/TeX-AMS-MML_HTMLorMML.js" integrity="sha256-84DKXVJXs0/F8OTMzX4UR909+jtl4G7SPypPavF+GfA=" crossorigin="anonymous"></script><!--[if lt IE 9]>
<script src="https://oss.maxcdn.com/html5shiv/3.7.3/html5shiv.min.js"></script>
<script src="https://oss.maxcdn.com/respond/1.4.2/respond.min.js"></script>
<![endif]-->
</head>
<body>
    <div class="container template-article">
      <header><div class="navbar navbar-default navbar-fixed-top" role="navigation">
  <div class="container">
    <div class="navbar-header">
      <button type="button" class="navbar-toggle collapsed" data-toggle="collapse" data-target="#navbar" aria-expanded="false">
        <span class="sr-only">Toggle navigation</span>
        <span class="icon-bar"></span>
        <span class="icon-bar"></span>
        <span class="icon-bar"></span>
      </button>
      <span class="navbar-brand">
        <a class="navbar-link" href="../index.html">fastshap</a>
        <span class="version label label-default" data-toggle="tooltip" data-placement="bottom" title="Released version">0.0.3</span>
      </span>
    </div>

    <div id="navbar" class="navbar-collapse collapse">
      <ul class="nav navbar-nav">
<li>
  <a href="../index.html">
    <span class="fas fa fas fa-home fa-lg"></span>
     
  </a>
</li>
<li>
  <a href="../articles/fastshap.html">Get started</a>
</li>
<li>
  <a href="../reference/index.html">Reference</a>
</li>
<li class="dropdown">
  <a href="#" class="dropdown-toggle" data-toggle="dropdown" role="button" aria-expanded="false">
    Articles
     
    <span class="caret"></span>
  </a>
  <ul class="dropdown-menu" role="menu">
<li>
      <a href="../articles/fastshap-vs-iml-iBreakDown.html">fastshap-vs-iml-iBreakDown</a>
    </li>
    <li>
      <a href="../articles/fastshap-vs-shap.html">fastshap-vs-shap</a>
    </li>
  </ul>
</li>
<li>
  <a href="../news/index.html">Changelog</a>
</li>
      </ul>
<ul class="nav navbar-nav navbar-right">
<li>
  <a href="https://github.com/bgreenwell/fastshap">
    <span class="fab fa fab fa-github fa-lg"></span>
     
  </a>
</li>
      </ul>
</div>
<!--/.nav-collapse -->
  </div>
<!--/.container -->
</div>
<!--/.navbar -->

      

      </header><div class="row">
  <div class="col-md-9 contents">
    <div class="page-header toc-ignore">
      <h1>fastshap</h1>
            
      
      <small class="dont-index">Source: <a href="https://github.com/bgreenwell/fastshap/blob/master/vignettes/fastshap.Rmd"><code>vignettes/fastshap.Rmd</code></a></small>
      <div class="hidden name"><code>fastshap.Rmd</code></div>

    </div>

    
    
<div id="background" class="section level2">
<h2 class="hasAnchor">
<a href="#background" class="anchor"></a>Background</h2>
<p>The approach in this package is similar to what’s described in <strong>Algorithm 1</strong> in Strumbelj and Kononenko (2014) which is reproduced below:</p>
<p><img src="basic-algorithm.png" width="468"></p>
<p>The problem with this approach is that it requires many calls to the scoring function <em>f()</em>. In particular, if we have <em>N</em> training records and <em>p</em> features, than this algorithm would require <em>2mnp</em> calls to <em>f()</em> in order to obtain approximate Shapley values for the entire training set. The approach we take is similar, but rather than computing each Monte Carlo estimate one at a time, we construct all the data required to compute the approximate Shapley values for a single feature at once and only use two calls to <em>f()</em>. Using this approach only requires <em>2mp</em> calls to <em>f()</em> to obtain approximate Shapley values for all <em>p</em> features for the entire training set. Hence, this approach will scale better to larger training sets. Also, the data instances <strong>b<sub>1</sub></strong> and <strong>b<sub>2</sub></strong> are built efficiently for each row in the training set (or subset thereof) all at once and stacked on top of each other in a data frame or matrix using C++ and logical subsetting. We can also parallelize the algorithm across <em>m</em> or <em>p</em>, depending on which one is more beneficial.</p>
<p><strong>NOTE:</strong> Although <a href="https://cran.r-project.org/package=fastshap">fastshap</a> efficiently employs the sampling approach to computing approximate Shapley values, the package also supports exact approaches for certain classes of linear models gradient boosted decision trees (e.g., <a href="https://cran.r-project.org/package=xgboost">xgboost</a>).</p>
</div>
<div id="example" class="section level2">
<h2 class="hasAnchor">
<a href="#example" class="anchor"></a>Example</h2>
<p>The following example demonstrates the basic usage of the <a href="https://cran.r-project.org/package=fastshap">fastshap</a> package.</p>
<div class="sourceCode" id="cb1"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb1-1" data-line-number="1"><span class="co"># Load required packages</span></a>
<a class="sourceLine" id="cb1-2" data-line-number="2"><span class="kw"><a href="https://rdrr.io/r/base/library.html">library</a></span>(fastshap)  <span class="co"># for fast (approximate) Shapley values</span></a>
<a class="sourceLine" id="cb1-3" data-line-number="3"><span class="kw"><a href="https://rdrr.io/r/base/library.html">library</a></span>(mlbench)   <span class="co"># for Friedman 1 benchmark data set</span></a>
<a class="sourceLine" id="cb1-4" data-line-number="4"><span class="kw"><a href="https://rdrr.io/r/base/library.html">library</a></span>(ranger)    <span class="co"># for fast random forest algorithm</span></a>
<a class="sourceLine" id="cb1-5" data-line-number="5"></a>
<a class="sourceLine" id="cb1-6" data-line-number="6"><span class="co"># Simulate training data</span></a>
<a class="sourceLine" id="cb1-7" data-line-number="7"><span class="kw"><a href="https://rdrr.io/r/base/Random.html">set.seed</a></span>(<span class="dv">101</span>)</a>
<a class="sourceLine" id="cb1-8" data-line-number="8">trn &lt;-<span class="st"> </span><span class="kw"><a href="https://rdrr.io/r/base/as.data.frame.html">as.data.frame</a></span>(<span class="kw"><a href="https://rdrr.io/pkg/mlbench/man/mlbench.friedman1.html">mlbench.friedman1</a></span>(<span class="dv">3000</span>))</a>
<a class="sourceLine" id="cb1-9" data-line-number="9">X &lt;-<span class="st"> </span><span class="kw"><a href="https://rdrr.io/r/base/subset.html">subset</a></span>(trn, <span class="dt">select =</span> <span class="op">-</span>y)  <span class="co"># feature columns only</span></a>
<a class="sourceLine" id="cb1-10" data-line-number="10"></a>
<a class="sourceLine" id="cb1-11" data-line-number="11"><span class="co"># Fit a random forest</span></a>
<a class="sourceLine" id="cb1-12" data-line-number="12"><span class="kw"><a href="https://rdrr.io/r/base/Random.html">set.seed</a></span>(<span class="dv">102</span>)</a>
<a class="sourceLine" id="cb1-13" data-line-number="13">rfo &lt;-<span class="st"> </span><span class="kw"><a href="https://rdrr.io/pkg/ranger/man/ranger.html">ranger</a></span>(y <span class="op">~</span><span class="st"> </span>., <span class="dt">data =</span>  trn)</a>
<a class="sourceLine" id="cb1-14" data-line-number="14"></a>
<a class="sourceLine" id="cb1-15" data-line-number="15"><span class="co"># Prediction wrapper</span></a>
<a class="sourceLine" id="cb1-16" data-line-number="16">pfun &lt;-<span class="st"> </span><span class="cf">function</span>(object, newdata) {</a>
<a class="sourceLine" id="cb1-17" data-line-number="17">  <span class="kw"><a href="https://rdrr.io/r/stats/predict.html">predict</a></span>(object, <span class="dt">data =</span> newdata)<span class="op">$</span>predictions</a>
<a class="sourceLine" id="cb1-18" data-line-number="18">}</a>
<a class="sourceLine" id="cb1-19" data-line-number="19"></a>
<a class="sourceLine" id="cb1-20" data-line-number="20"><span class="co"># Compute fast (approximate) Shapley values using 10 Monte Carlo repetitions</span></a>
<a class="sourceLine" id="cb1-21" data-line-number="21"><span class="kw"><a href="https://rdrr.io/r/base/system.time.html">system.time</a></span>({  <span class="co"># estimate run time</span></a>
<a class="sourceLine" id="cb1-22" data-line-number="22">  <span class="kw"><a href="https://rdrr.io/r/base/Random.html">set.seed</a></span>(<span class="dv">5038</span>)</a>
<a class="sourceLine" id="cb1-23" data-line-number="23">  shap &lt;-<span class="st"> </span><span class="kw"><a href="../reference/explain.html">explain</a></span>(rfo, <span class="dt">X =</span> X, <span class="dt">pred_wrapper =</span> pfun, <span class="dt">nsim =</span> <span class="dv">10</span>)</a>
<a class="sourceLine" id="cb1-24" data-line-number="24">})</a>
<a class="sourceLine" id="cb1-25" data-line-number="25"><span class="co">#&gt;    user  system elapsed </span></a>
<a class="sourceLine" id="cb1-26" data-line-number="26"><span class="co">#&gt;  90.000   1.339  18.477</span></a>
<a class="sourceLine" id="cb1-27" data-line-number="27"></a>
<a class="sourceLine" id="cb1-28" data-line-number="28"><span class="co"># Results are returned as a tibble (with the additional "shap" class)</span></a>
<a class="sourceLine" id="cb1-29" data-line-number="29">shap</a>
<a class="sourceLine" id="cb1-30" data-line-number="30"><span class="co">#&gt; # A tibble: 3,000 x 10</span></a>
<a class="sourceLine" id="cb1-31" data-line-number="31"><span class="co">#&gt;        x.1    x.2     x.3      x.4     x.5     x.6      x.7      x.8     x.9</span></a>
<a class="sourceLine" id="cb1-32" data-line-number="32"><span class="co">#&gt;      &lt;dbl&gt;  &lt;dbl&gt;   &lt;dbl&gt;    &lt;dbl&gt;   &lt;dbl&gt;   &lt;dbl&gt;    &lt;dbl&gt;    &lt;dbl&gt;   &lt;dbl&gt;</span></a>
<a class="sourceLine" id="cb1-33" data-line-number="33"><span class="co">#&gt;  1 -0.0894  0.839 -0.438  -3.21     0.0344 -0.110   2.00e-4 -1.82e-4 -0.0865</span></a>
<a class="sourceLine" id="cb1-34" data-line-number="34"><span class="co">#&gt;  2 -4.39    1.11   1.01   -0.00996  1.13   -0.0195  1.41e-1 -5.47e-2  0.109 </span></a>
<a class="sourceLine" id="cb1-35" data-line-number="35"><span class="co">#&gt;  3  1.35    1.72  -1.11   -3.47    -0.739  -0.0468  7.94e-3 -1.55e-2  0.0524</span></a>
<a class="sourceLine" id="cb1-36" data-line-number="36"><span class="co">#&gt;  4  1.72   -3.24  -0.293   3.37     0.320   0.0329  8.20e-2  2.14e-2  0.0457</span></a>
<a class="sourceLine" id="cb1-37" data-line-number="37"><span class="co">#&gt;  5 -1.54   -1.96   0.0507  3.72     1.64   -0.0377  1.91e-2  8.76e-2  0.0454</span></a>
<a class="sourceLine" id="cb1-38" data-line-number="38"><span class="co">#&gt;  6 -0.979   1.22  -1.00   -1.60     1.15    0.0607  8.84e-3 -2.02e-3 -0.157 </span></a>
<a class="sourceLine" id="cb1-39" data-line-number="39"><span class="co">#&gt;  7  0.650   2.03   1.44   -3.25    -0.0564  0.0859  6.81e-2  7.19e-2  0.0830</span></a>
<a class="sourceLine" id="cb1-40" data-line-number="40"><span class="co">#&gt;  8 -1.22   -1.88   0.304   4.86    -0.0709 -0.0442 -7.67e-3 -3.37e-2 -0.0326</span></a>
<a class="sourceLine" id="cb1-41" data-line-number="41"><span class="co">#&gt;  9  1.59    1.22  -0.548   3.60    -0.765   0.0583 -1.11e-1 -6.25e-3  0.132 </span></a>
<a class="sourceLine" id="cb1-42" data-line-number="42"><span class="co">#&gt; 10  1.10   -2.36  -1.15   -1.49     0.927  -0.0437 -3.44e-2  3.01e-2 -0.142 </span></a>
<a class="sourceLine" id="cb1-43" data-line-number="43"><span class="co">#&gt; # … with 2,990 more rows, and 1 more variable: x.10 &lt;dbl&gt;</span></a></code></pre></div>
<p>You can use the results to help interpret the model in many different ways. For example, in the code chunk below we take the sum of the absolute value of the Shapley values within each feature to construct a Shap-based feature variable importance plot:</p>
<div class="sourceCode" id="cb2"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb2-1" data-line-number="1"><span class="co"># Load required packages</span></a>
<a class="sourceLine" id="cb2-2" data-line-number="2"><span class="kw"><a href="https://rdrr.io/r/base/library.html">library</a></span>(ggplot2)</a>
<a class="sourceLine" id="cb2-3" data-line-number="3"><span class="kw"><a href="https://ggplot2.tidyverse.org/reference/theme_get.html">theme_set</a></span>(<span class="kw"><a href="https://ggplot2.tidyverse.org/reference/ggtheme.html">theme_bw</a></span>())</a>
<a class="sourceLine" id="cb2-4" data-line-number="4"></a>
<a class="sourceLine" id="cb2-5" data-line-number="5"><span class="co"># Aggregate Shapley values</span></a>
<a class="sourceLine" id="cb2-6" data-line-number="6">shap_imp &lt;-<span class="st"> </span><span class="kw"><a href="https://rdrr.io/r/base/data.frame.html">data.frame</a></span>(</a>
<a class="sourceLine" id="cb2-7" data-line-number="7">  <span class="dt">Variable =</span> <span class="kw"><a href="https://rdrr.io/r/base/names.html">names</a></span>(shap),</a>
<a class="sourceLine" id="cb2-8" data-line-number="8">  <span class="dt">Importance =</span> <span class="kw"><a href="https://rdrr.io/r/base/apply.html">apply</a></span>(shap, <span class="dt">MARGIN =</span> <span class="dv">2</span>, <span class="dt">FUN =</span> <span class="cf">function</span>(x) <span class="kw"><a href="https://rdrr.io/r/base/sum.html">sum</a></span>(<span class="kw"><a href="https://rdrr.io/r/base/MathFun.html">abs</a></span>(x)))</a>
<a class="sourceLine" id="cb2-9" data-line-number="9">)</a>
<a class="sourceLine" id="cb2-10" data-line-number="10"></a>
<a class="sourceLine" id="cb2-11" data-line-number="11"><span class="co"># Plot Shap-based variable importance</span></a>
<a class="sourceLine" id="cb2-12" data-line-number="12"><span class="kw"><a href="https://ggplot2.tidyverse.org/reference/ggplot.html">ggplot</a></span>(shap_imp, <span class="kw"><a href="https://ggplot2.tidyverse.org/reference/aes.html">aes</a></span>(<span class="kw"><a href="https://rdrr.io/r/stats/reorder.factor.html">reorder</a></span>(Variable, Importance), Importance)) <span class="op">+</span></a>
<a class="sourceLine" id="cb2-13" data-line-number="13"><span class="st">  </span><span class="kw"><a href="https://ggplot2.tidyverse.org/reference/geom_bar.html">geom_col</a></span>() <span class="op">+</span></a>
<a class="sourceLine" id="cb2-14" data-line-number="14"><span class="st">  </span><span class="kw"><a href="https://ggplot2.tidyverse.org/reference/coord_flip.html">coord_flip</a></span>() <span class="op">+</span></a>
<a class="sourceLine" id="cb2-15" data-line-number="15"><span class="st">  </span><span class="kw"><a href="https://ggplot2.tidyverse.org/reference/labs.html">xlab</a></span>(<span class="st">""</span>) <span class="op">+</span></a>
<a class="sourceLine" id="cb2-16" data-line-number="16"><span class="st">  </span><span class="kw"><a href="https://ggplot2.tidyverse.org/reference/labs.html">ylab</a></span>(<span class="st">"mean(|Shapley value|)"</span>)</a></code></pre></div>
<p><img src="fastshap_files/figure-html/shap-importance-1.png" width="70%"></p>
<p>We can also plot the Shapley values for each feature to construct Shap-based dependence plots:</p>
<div class="sourceCode" id="cb3"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb3-1" data-line-number="1">shap_dep_x3 &lt;-<span class="st"> </span><span class="kw"><a href="https://rdrr.io/r/base/data.frame.html">data.frame</a></span>(<span class="dt">x3 =</span> X[[<span class="st">"x.3"</span>]], <span class="dt">shap =</span> shap[[<span class="st">"x.3"</span>]])</a>
<a class="sourceLine" id="cb3-2" data-line-number="2"><span class="kw"><a href="https://ggplot2.tidyverse.org/reference/ggplot.html">ggplot</a></span>(shap_dep_x3, <span class="kw"><a href="https://ggplot2.tidyverse.org/reference/aes.html">aes</a></span>(x3, shap)) <span class="op">+</span></a>
<a class="sourceLine" id="cb3-3" data-line-number="3"><span class="st">  </span><span class="kw"><a href="https://ggplot2.tidyverse.org/reference/geom_point.html">geom_point</a></span>(<span class="dt">alpha =</span> <span class="fl">0.3</span>) <span class="op">+</span></a>
<a class="sourceLine" id="cb3-4" data-line-number="4"><span class="st">  </span><span class="kw"><a href="https://ggplot2.tidyverse.org/reference/geom_smooth.html">geom_smooth</a></span>() <span class="op">+</span></a>
<a class="sourceLine" id="cb3-5" data-line-number="5"><span class="st">  </span><span class="kw"><a href="https://ggplot2.tidyverse.org/reference/labs.html">ylab</a></span>(<span class="st">"Shapley value"</span>)</a>
<a class="sourceLine" id="cb3-6" data-line-number="6"><span class="co">#&gt; `geom_smooth()` using method = 'gam' and formula 'y ~ s(x, bs = "cs")'</span></a></code></pre></div>
<p><img src="fastshap_files/figure-html/shap-dependence-1.png" width="70%"></p>
<p>You can also use <code><a href="https://ggplot2.tidyverse.org/reference/autoplot.html">autoplot()</a></code> to construct simple plots:</p>
<div class="sourceCode" id="cb4"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb4-1" data-line-number="1">p1 &lt;-<span class="st"> </span><span class="kw"><a href="https://ggplot2.tidyverse.org/reference/autoplot.html">autoplot</a></span>(shap)</a>
<a class="sourceLine" id="cb4-2" data-line-number="2">p2 &lt;-<span class="st"> </span><span class="kw"><a href="https://ggplot2.tidyverse.org/reference/autoplot.html">autoplot</a></span>(shap, <span class="dt">type =</span> <span class="st">"dependence"</span>, <span class="dt">feature =</span> <span class="st">"x.3"</span>, <span class="dt">X =</span> X, <span class="dt">alpha =</span> <span class="fl">0.5</span>,</a>
<a class="sourceLine" id="cb4-3" data-line-number="3">               <span class="dt">color_by =</span> <span class="st">"x.2"</span>, <span class="dt">smooth =</span> <span class="ot">TRUE</span>, <span class="dt">smooth_color =</span> <span class="st">"black"</span>) <span class="op">+</span></a>
<a class="sourceLine" id="cb4-4" data-line-number="4"><span class="st">        </span><span class="kw"><a href="https://ggplot2.tidyverse.org/reference/scale_viridis.html">scale_color_viridis_c</a></span>()</a>
<a class="sourceLine" id="cb4-5" data-line-number="5">gridExtra<span class="op">::</span><span class="kw"><a href="https://rdrr.io/pkg/gridExtra/man/arrangeGrob.html">grid.arrange</a></span>(p1, p2, <span class="dt">nrow =</span> <span class="dv">1</span>)</a>
<a class="sourceLine" id="cb4-6" data-line-number="6"><span class="co">#&gt; `geom_smooth()` using method = 'gam' and formula 'y ~ s(x, bs = "cs")'</span></a></code></pre></div>
<p><img src="fastshap_files/figure-html/shap-autoplot-1.png" width="70%"></p>
<p>By default, <code><a href="../reference/explain.html">explain()</a></code> computes approximate Shapley values for all rows in the training data. If you want Shapley values for new instances (or a subset of the training set), they must be supplied via the <code>newdata</code> argument. This functionality is demonstrated in the code chunk below. (<strong>NOTE:</strong> <code><a href="../reference/explain.html">explain()</a></code> is not yet optimized for this case; that is, computing only a handful of Shapley values for a few instances (in this case, at least for now, consider using the <a href="https://cran.r-project.org/package=iml">iml</a> function <code>Shapley()</code>).)</p>
<div class="sourceCode" id="cb5"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb5-1" data-line-number="1"><span class="co"># Explanations for first observation; technically `drop = FALSE` isn't necessary </span></a>
<a class="sourceLine" id="cb5-2" data-line-number="2"><span class="co"># here since X is a data frame</span></a>
<a class="sourceLine" id="cb5-3" data-line-number="3"><span class="kw"><a href="../reference/explain.html">explain</a></span>(rfo, <span class="dt">X =</span> X, <span class="dt">pred_wrapper =</span> pfun, <span class="dt">nsim =</span> <span class="dv">10</span>,</a>
<a class="sourceLine" id="cb5-4" data-line-number="4">        <span class="dt">newdata =</span> X[<span class="dv">1</span>, , <span class="dt">drop =</span> <span class="ot">FALSE</span>])</a>
<a class="sourceLine" id="cb5-5" data-line-number="5"><span class="co">#&gt; # A tibble: 1 x 10</span></a>
<a class="sourceLine" id="cb5-6" data-line-number="6"><span class="co">#&gt;      x.1   x.2    x.3   x.4    x.5     x.6     x.7    x.8    x.9     x.10</span></a>
<a class="sourceLine" id="cb5-7" data-line-number="7"><span class="co">#&gt;    &lt;dbl&gt; &lt;dbl&gt;  &lt;dbl&gt; &lt;dbl&gt;  &lt;dbl&gt;   &lt;dbl&gt;   &lt;dbl&gt;  &lt;dbl&gt;  &lt;dbl&gt;    &lt;dbl&gt;</span></a>
<a class="sourceLine" id="cb5-8" data-line-number="8"><span class="co">#&gt; 1 -0.391 0.987 -0.595 -2.74 -0.378 -0.0563 -0.0205 0.0456 0.0363 -0.00262</span></a>
<a class="sourceLine" id="cb5-9" data-line-number="9"></a>
<a class="sourceLine" id="cb5-10" data-line-number="10"><span class="co"># Explanations for first three observations</span></a>
<a class="sourceLine" id="cb5-11" data-line-number="11"><span class="kw"><a href="../reference/explain.html">explain</a></span>(rfo, <span class="dt">X =</span> X, <span class="dt">feature_names =</span> <span class="kw"><a href="https://rdrr.io/r/base/c.html">c</a></span>(<span class="st">"x.1"</span>, <span class="st">"x.10"</span>), <span class="dt">pred_wrapper =</span> pfun, </a>
<a class="sourceLine" id="cb5-12" data-line-number="12">        <span class="dt">nsim =</span> <span class="dv">10</span>, <span class="dt">newdata =</span> X[<span class="dv">1</span><span class="op">:</span><span class="dv">3</span>, ])</a>
<a class="sourceLine" id="cb5-13" data-line-number="13"><span class="co">#&gt; # A tibble: 3 x 2</span></a>
<a class="sourceLine" id="cb5-14" data-line-number="14"><span class="co">#&gt;     x.1     x.10</span></a>
<a class="sourceLine" id="cb5-15" data-line-number="15"><span class="co">#&gt;   &lt;dbl&gt;    &lt;dbl&gt;</span></a>
<a class="sourceLine" id="cb5-16" data-line-number="16"><span class="co">#&gt; 1 -1.49 -0.0265 </span></a>
<a class="sourceLine" id="cb5-17" data-line-number="17"><span class="co">#&gt; 2 -4.53  0.00751</span></a>
<a class="sourceLine" id="cb5-18" data-line-number="18"><span class="co">#&gt; 3  1.33  0.0690</span></a>
<a class="sourceLine" id="cb5-19" data-line-number="19"></a>
<a class="sourceLine" id="cb5-20" data-line-number="20"><span class="co"># Plot individual explanations</span></a>
<a class="sourceLine" id="cb5-21" data-line-number="21">expl &lt;-<span class="st"> </span><span class="kw"><a href="../reference/explain.html">explain</a></span>(rfo, <span class="dt">X =</span> X,<span class="dt">pred_wrapper =</span> pfun, <span class="dt">nsim =</span> <span class="dv">10</span>, <span class="dt">newdata =</span> X[1L, ])</a>
<a class="sourceLine" id="cb5-22" data-line-number="22"><span class="kw"><a href="https://ggplot2.tidyverse.org/reference/autoplot.html">autoplot</a></span>(expl, <span class="dt">type =</span> <span class="st">"contribution"</span>)</a></code></pre></div>
<p><img src="fastshap_files/figure-html/shap-newdata-1.png" width="70%"></p>
<div id="parallel-execution" class="section level3">
<h3 class="hasAnchor">
<a href="#parallel-execution" class="anchor"></a>Parallel execution</h3>
<p>With <a href="https://cran.r-project.org/package=fastshap">fastshap</a> you can compute contributions for multiple features in parallel using any parallel backend supported by the <a href="https://cran.r-project.org/package=foreach">foreach</a> package. This is illustrated in the code chunk below.</p>
<div class="sourceCode" id="cb6"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb6-1" data-line-number="1"><span class="co"># Load required packages</span></a>
<a class="sourceLine" id="cb6-2" data-line-number="2"><span class="kw"><a href="https://rdrr.io/r/base/library.html">library</a></span>(doParallel)</a>
<a class="sourceLine" id="cb6-3" data-line-number="3"></a>
<a class="sourceLine" id="cb6-4" data-line-number="4"><span class="co"># Set up parallel backend</span></a>
<a class="sourceLine" id="cb6-5" data-line-number="5">cl &lt;-<span class="st"> </span><span class="cf">if</span> (.Platform<span class="op">$</span>OS.type <span class="op">==</span><span class="st"> "unix"</span>) <span class="dv">8</span> <span class="cf">else</span> <span class="kw">makeCluster</span>(<span class="dv">8</span>)</a>
<a class="sourceLine" id="cb6-6" data-line-number="6"><span class="kw"><a href="https://rdrr.io/pkg/doParallel/man/registerDoParallel.html">registerDoParallel</a></span>(cl)</a>
<a class="sourceLine" id="cb6-7" data-line-number="7"></a>
<a class="sourceLine" id="cb6-8" data-line-number="8"><span class="co"># Compute Shapley values in parallel</span></a>
<a class="sourceLine" id="cb6-9" data-line-number="9"><span class="kw"><a href="../reference/explain.html">explain</a></span>(rfo, <span class="dt">X =</span> X, <span class="dt">pred_wrapper =</span> pfun, <span class="dt">nsim =</span> <span class="dv">10</span>, <span class="dt">.parallel =</span> <span class="ot">TRUE</span>)</a>
<a class="sourceLine" id="cb6-10" data-line-number="10"><span class="co">#&gt; # A tibble: 3,000 x 10</span></a>
<a class="sourceLine" id="cb6-11" data-line-number="11"><span class="co">#&gt;        x.1    x.2    x.3    x.4     x.5      x.6      x.7     x.8      x.9</span></a>
<a class="sourceLine" id="cb6-12" data-line-number="12"><span class="co">#&gt;      &lt;dbl&gt;  &lt;dbl&gt;  &lt;dbl&gt;  &lt;dbl&gt;   &lt;dbl&gt;    &lt;dbl&gt;    &lt;dbl&gt;   &lt;dbl&gt;    &lt;dbl&gt;</span></a>
<a class="sourceLine" id="cb6-13" data-line-number="13"><span class="co">#&gt;  1  0.0112  0.839 -1.02  -1.95   0.497   1.32e-2 -0.00378 -0.0302 -0.106  </span></a>
<a class="sourceLine" id="cb6-14" data-line-number="14"><span class="co">#&gt;  2 -4.08    1.49   0.509 -0.527  2.16    5.88e-2  0.0816  -0.0338 -0.0483 </span></a>
<a class="sourceLine" id="cb6-15" data-line-number="15"><span class="co">#&gt;  3  1.73    2.33  -1.20  -4.42  -1.25   -8.50e-4  0.0250  -0.0803 -0.0126 </span></a>
<a class="sourceLine" id="cb6-16" data-line-number="16"><span class="co">#&gt;  4  2.39   -1.27   0.110  3.84   1.24    3.64e-3 -0.00605  0.0286  0.0469 </span></a>
<a class="sourceLine" id="cb6-17" data-line-number="17"><span class="co">#&gt;  5 -1.38   -0.855 -0.224  2.17   0.308   1.58e-2  0.0869   0.0798  0.00112</span></a>
<a class="sourceLine" id="cb6-18" data-line-number="18"><span class="co">#&gt;  6  1.60    1.35  -0.876 -2.41   1.28    9.94e-2  0.0488  -0.133  -0.158  </span></a>
<a class="sourceLine" id="cb6-19" data-line-number="19"><span class="co">#&gt;  7  1.43    2.30   1.07  -3.77  -0.915  -1.10e-2 -0.0665  -0.0145  0.00386</span></a>
<a class="sourceLine" id="cb6-20" data-line-number="20"><span class="co">#&gt;  8 -0.875  -1.01   0.538  2.49   0.0828  1.51e-2  0.00551  0.0379  0.0398 </span></a>
<a class="sourceLine" id="cb6-21" data-line-number="21"><span class="co">#&gt;  9  2.58    2.84  -0.797  4.22  -1.30    2.16e-2  0.0337  -0.0454  0.0304 </span></a>
<a class="sourceLine" id="cb6-22" data-line-number="22"><span class="co">#&gt; 10  1.14   -3.18  -0.550 -3.47   1.09   -4.58e-2 -0.0516   0.0110 -0.134  </span></a>
<a class="sourceLine" id="cb6-23" data-line-number="23"><span class="co">#&gt; # … with 2,990 more rows, and 1 more variable: x.10 &lt;dbl&gt;</span></a></code></pre></div>
</div>
</div>
<div id="comparison-with-treeshaptreeexplainer-for-xgboost-models" class="section level2">
<h2 class="hasAnchor">
<a href="#comparison-with-treeshaptreeexplainer-for-xgboost-models" class="anchor"></a>Comparison with TreeSHAP/TreeExplainer for XGBoost models</h2>
<p>You can compute the contributions of each feature for XGBoost models in an efficient way using the methods described in <a href="https://arxiv.org/abs/1705.07874">(Lundberg 2017)</a>. These are available through the <code><a href="https://rdrr.io/r/stats/predict.html">predict()</a></code> function for <a href="https://cran.r-project.org/package=xgboost">xgboost</a> models; see <code><a href="https://rdrr.io/pkg/xgboost/man/predict.xgb.Booster.html">?xgboost::predict.xgb.Booster</a></code> for details. Below we compute the contributions for each feature using both methods and compare the results using a Shapley-based dependence plot on feature <code>x.3</code>, the results are quite surprising (<strong>no parallel processing was used to obtain the <a href="https://cran.r-project.org/package=fastshap">fastshap</a> results</strong>). And remember, <a href="https://cran.r-project.org/package=fastshap">fastshap</a> can be used with any prediction model in R.</p>
<p><img src="fastshap_files/figure-html/fastshap-comparison-1.png" width="70%"></p>
<p>We can also check that <a href="https://cran.r-project.org/package=fastshap">fastshap</a> converges to the true Shapley values by comparing the results to TreeSHAP while varying the number of Monte Carlo repetitions:</p>
<p><img src="fastshap_files/figure-html/fastshap-convergence-1.png" width="70%"></p>
<p>Finally, starting with <a href="https://cran.r-project.org/package=fastshap">fastshap</a> version 0.0.4, you can request exact Shapley values for <a href="https://cran.r-project.org/package=xgboost">xgboost</a> and linear models (i.e., models fit using <code><a href="https://rdrr.io/r/stats/lm.html">stats::lm()</a></code> and <code><a href="https://rdrr.io/r/stats/glm.html">stats::glm()</a></code>). This is illustrated in the code chunk below where we use <code><a href="../reference/explain.html">fastshap::explain()</a></code> to compute exact explanations using TreeSHAP from the previously fitted <a href="https://cran.r-project.org/package=xgboost">xgboost</a> model.</p>
<div class="sourceCode" id="cb7"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb7-1" data-line-number="1"><span class="kw"><a href="https://rdrr.io/r/base/system.time.html">system.time</a></span>({</a>
<a class="sourceLine" id="cb7-2" data-line-number="2">  shap &lt;-<span class="st"> </span><span class="kw"><a href="../reference/explain.html">explain</a></span>(bst, <span class="dt">X =</span> <span class="kw"><a href="https://rdrr.io/r/base/data.matrix.html">data.matrix</a></span>(X), <span class="dt">pred_wrapper =</span> pfun, <span class="dt">exact =</span> <span class="ot">TRUE</span>)</a>
<a class="sourceLine" id="cb7-3" data-line-number="3">})</a>
<a class="sourceLine" id="cb7-4" data-line-number="4"><span class="co">#&gt; [15:32:10] </span><span class="al">WARNING</span><span class="co">: amalgamation/../src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.</span></a>
<a class="sourceLine" id="cb7-5" data-line-number="5"><span class="co">#&gt;    user  system elapsed </span></a>
<a class="sourceLine" id="cb7-6" data-line-number="6"><span class="co">#&gt;   0.280   0.009   0.304</span></a>
<a class="sourceLine" id="cb7-7" data-line-number="7"><span class="kw"><a href="https://ggplot2.tidyverse.org/reference/autoplot.html">autoplot</a></span>(shap)</a></code></pre></div>
<p><img src="fastshap_files/figure-html/fastshap-exact-1.png" width="70%"></p>
</div>
<div id="references" class="section level2">
<h2 class="hasAnchor">
<a href="#references" class="anchor"></a>References</h2>
<p>Scott M. Lundberg, Su-In Lee, “A Unified Approach to Interpreting Model Predictions”, NIPS Proceedings 2017, <a href="https://arxiv.org/abs/1705.07874" class="uri">https://arxiv.org/abs/1705.07874</a>.</p>
<p>Scott M. Lundberg, Su-In Lee, “Consistent feature attribution for tree ensembles”, <a href="https://arxiv.org/abs/1706.06060" class="uri">https://arxiv.org/abs/1706.06060</a>.</p>
<p>Christoph Molnar, <em>Interpretable Machine Learning</em>. 2019. <a href="https://christophm.github.io/interpretable-ml-" class="uri">https://christophm.github.io/interpretable-ml-</a> book/.</p>
</div>
  </div>

  <div class="col-md-3 hidden-xs hidden-sm" id="sidebar">

        <div id="tocnav">
      <h2 class="hasAnchor">
<a href="#tocnav" class="anchor"></a>Contents</h2>
      <ul class="nav nav-pills nav-stacked">
<li><a href="#background">Background</a></li>
      <li><a href="#example">Example</a></li>
      <li><a href="#comparison-with-treeshaptreeexplainer-for-xgboost-models">Comparison with TreeSHAP/TreeExplainer for XGBoost models</a></li>
      <li><a href="#references">References</a></li>
      </ul>
</div>
      </div>

</div>



      <footer><div class="copyright">
  <p>Developed by Brandon Greenwell.</p>
</div>

<div class="pkgdown">
  <p>Site built with <a href="https://pkgdown.r-lib.org/">pkgdown</a> 1.4.1.</p>
</div>

      </footer>
</div>

  


  </body>
</html>
